{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from numba import jit, njit, prange\n",
    "\n",
    "#################### Macros #############################\n",
    "np.random.seed(0)\n",
    "\n",
    "# Physical constants\n",
    "K=12 # number of fermionic modes <-- They use K=17 in the paper\n",
    "BETA = 5 # inverse temperature\n",
    "N = 2*K # number of fermions\n",
    "N_DIM = 2**K # Hilbert space dimensions\n",
    "J=4 # ~\"energy scale\" <-- Their J not given in the paper, nor whether we're even in strong or weak-coupling regime. Maybe all that matters is t*J, which is what they plot?\n",
    "Q=4 # order of coupling <-- Their q also not given. 4 is pretty generic, so let's stick with that \n",
    "E_ORDER = 13 # Order to keep of matrix-exponential expansion. Also not given in the paper. \n",
    "\n",
    "# Directory to save sample Hamiltonians\n",
    "H_DIR = os.path.join(\"Simulated Hamiltonians\", f\"H4_K{K}_J{J}_Q{Q}\")\n",
    "os.makedirs(H_DIR, exist_ok=True)\n",
    "\n",
    "N_SAMPLES = 160 # number of samples to generate\n",
    "N_JOBS = 20 # number of jobs to run in parallel\n",
    "\n",
    "################## Locals #############################\n",
    "from hamiltonian_generation import make_H4_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-computed sample Hamiltonians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See notebook: \"computing_eigenvalues_for_unfolding.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_all= np.zeros((N_SAMPLES, N_DIM, N_DIM), dtype=np.complex128) \n",
    "#iv_all = np.zeros((N_SAMPLES, N_DIM), dtype=np.float64) # iv = eigenvalues\n",
    "for i in range(N_SAMPLES):\n",
    "    H_all[i] = np.load(os.path.join(H_DIR, f\"H4_{i+1}.npy\"))\n",
    "    #iv_all[i] = np.linalg.eigvalsh(H_all[i])\n",
    "\n",
    "iv_all = np.load(os.path.join(H_DIR, \"eigenvalues_all.npy\"))\n",
    "#np.save(os.path.join(H_DIR, \"eigenvalues_all.npy\"), iv_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = np.random.choice(N_SAMPLES)\n",
    "H_test = H_all[test_index]\n",
    "iv_test = iv_all[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense: 0.0 minutes, 32.00787019729614 seconds\n"
     ]
    }
   ],
   "source": [
    "def matrix_exponential(A, n): # A = matrix, n = order of expansion\n",
    "    out = np.zeros(A.shape, dtype=np.complex128)\n",
    "    last_term = np.identity(A.shape[0])\n",
    "    out += last_term\n",
    "    for i in range(1, n+1):\n",
    "        last_term = last_term @ A / i\n",
    "        out += last_term\n",
    "        \n",
    "    return out\n",
    "\n",
    "tic = time.time()\n",
    "e_to_H = matrix_exponential(H_test, E_ORDER)\n",
    "toc = time.time()\n",
    "duration = toc - tic\n",
    "print(f\"Dense: {duration//60} minutes, {duration%60} seconds\")\n",
    "\n",
    "later = \"\"\"\n",
    "def matrix_exponential_sparse(A, n): # A = matrix, n = order of expansion\n",
    "    out = sparse.csr_array(np.zeros(A.shape, dtype=np.complex128))\n",
    "    last_term = sparse.csr_array(np.identity(A.shape[0]))\n",
    "    out += last_term\n",
    "    for i in range(1, n+1):\n",
    "        last_term = last_term @ A / i\n",
    "        out += last_term\n",
    "        \n",
    "    return out\n",
    "\n",
    "H_test_sparse = sparse.csr_array(H_test)\n",
    "tic = time.time()\n",
    "e_to_H_sparse = matrix_exponential_sparse(H_test_sparse, E_ORDER)\n",
    "toc = time.time()\n",
    "duration = toc - tic\n",
    "print(f\"Sparse: {duration//60} minutes, {duration%60} seconds\")\n",
    "\n",
    "\n",
    "print(np.allclose(e_to_H, e_to_H_sparse.toarray()))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare how close self-defined matrix-exponential is with scipy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy: 1.0 minutes, 54.3090660572052 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "e_to_H_scipy = expm(H_test)\n",
    "toc = time.time()\n",
    "duration = toc - tic\n",
    "print(f\"Scipy: {duration//60} minutes, {duration%60} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy function too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"E_ORDER: {E_ORDER}\")\n",
    "print(\"allclose: \", np.allclose(e_to_H, e_to_H_scipy))\n",
    "\n",
    "abs_diff = np.abs(e_to_H - e_to_H_scipy)\n",
    "print(\"max_abs_diff: \", np.max(np.max(abs_diff, axis=0), axis=0))\n",
    "print(\"sum_abs_diff: \", np.sum(np.sum(abs_diff, axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the sum of the absolute difference to be at least (a few orders of magnitude) smaller than the Hilbert space dimension (4096)\n",
    "\n",
    "E_ORDER=6: sum_abs_diff = 248906, time = 15.4 seconds\n",
    "\n",
    "E_ORDER=10: sum_abs_diff = 8483, time = 23.5 seconds\n",
    "\n",
    "E_ORDER=12: sum_abs_diff = 970, time = 30 seconds\n",
    "\n",
    "E_ORDER=13: sum_abs_diff = 6e-4, time = 31 seconds\n",
    "\n",
    "E_ORDER=15: sum_abs_diff = 5e-5, time = 36.6 seconds\n",
    "\n",
    "E_ORDER=20: sum_abs_diff = 1.5e-8, time = 58 seconds\n",
    "\n",
    "E_ORDER=13 seems optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick check to see if sparse matrix-exponential is faster (it's probably not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_ORDER = 13\n",
    "print(f\"E_ORDER: {E_ORDER}\")\n",
    "\n",
    "tic = time.time()\n",
    "e_to_H_sparse = matrix_exponential_sparse(H_test_sparse, E_ORDER)\n",
    "toc = time.time()\n",
    "duration = toc - tic\n",
    "print(f\"Dense: {duration//60} minutes, {duration%60} seconds\")\n",
    "\n",
    "e_to_H_sparse = e_to_H_sparse.toarray()\n",
    "print(\"allclose: \", np.allclose(e_to_H_sparse, e_to_H_scipy))\n",
    "\n",
    "abs_diff = np.abs(e_to_H_sparse - e_to_H_scipy)\n",
    "print(\"max_abs_diff: \", np.max(np.max(abs_diff, axis=0), axis=0))\n",
    "print(\"sum_abs_diff: \", np.sum(np.sum(abs_diff, axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Not sure *why* it's slower... \n",
    "Also has larger error relative to non-sparse version..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define spectral form factor, disorder-averaged analogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straightforward version, proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m g\n\u001b[0;32m     24\u001b[0m test_t \u001b[39m=\u001b[39m \u001b[39m12\u001b[39m\n\u001b[1;32m---> 25\u001b[0m g_test \u001b[39m=\u001b[39m g(H_all, test_t)\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mg\u001b[1;34m(H_all, t)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(H_all\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     11\u001b[0m     H_i \u001b[39m=\u001b[39m H_all[i]\n\u001b[1;32m---> 12\u001b[0m     Zt_i \u001b[39m=\u001b[39m Zt(H_i, t)\n\u001b[0;32m     13\u001b[0m     g_num \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m Zt_i\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mconj(Zt_i)\n\u001b[0;32m     15\u001b[0m     sqrt_g_den \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m Z(H_i)\n",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36mZt\u001b[1;34m(H, t)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mZt\u001b[39m(H,t):\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mtrace(matrix_exponential(\u001b[39m-\u001b[39;49m(BETA\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49mj\u001b[39m*\u001b[39;49mt)\u001b[39m*\u001b[39;49mH, E_ORDER))\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mmatrix_exponential\u001b[1;34m(A, n)\u001b[0m\n\u001b[0;32m      4\u001b[0m out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m last_term\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     last_term \u001b[39m=\u001b[39m last_term \u001b[39m@\u001b[39;49m A \u001b[39m/\u001b[39m i\n\u001b[0;32m      7\u001b[0m     out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m last_term\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Z(H):\n",
    "    return np.trace(matrix_exponential(-BETA*H, E_ORDER))\n",
    "\n",
    "def Zt(H,t):\n",
    "    return np.trace(matrix_exponential(-(BETA+1j*t)*H, E_ORDER))\n",
    "\n",
    "def g(H_all, t):\n",
    "    g_num = np.zeros((H_all.shape[1], H_all.shape[2]), dtype=np.complex128)\n",
    "    sqrt_g_den = np.zeros((H_all.shape[1], H_all.shape[2]), dtype=np.complex128)\n",
    "    for i in range(H_all.shape[0]):\n",
    "        H_i = H_all[i]\n",
    "        Zt_i = Zt(H_i, t)\n",
    "        g_num += Zt_i*np.conj(Zt_i)\n",
    "\n",
    "        sqrt_g_den += Z(H_i)\n",
    "    \n",
    "    g_num *= 1/H_all.shape[0]\n",
    "    sqrt_g_den *= 1/H_all.shape[0]\n",
    "    g_den = sqrt_g_den**2\n",
    "\n",
    "    g = g_num/g_den\n",
    "    return g\n",
    "\n",
    "test_t = 12\n",
    "\n",
    "tic = time.time()\n",
    "g_test = g(H_all, test_t)\n",
    "toc = time.time()\n",
    "duration = toc - tic\n",
    "print(f\"Single time-step, no parallelization: {duration//60} minutes, {duration%60} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking too long so I quit it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z(H):\n",
    "    return np.trace(matrix_exponential(-BETA*H, E_ORDER))\n",
    "\n",
    "def Zt(H,t):\n",
    "    return np.trace(matrix_exponential(-(BETA+1j*t)*H, E_ORDER))\n",
    "\n",
    "def g_i(H_i, t, g_num_all, sqrt_g_den_all, i): # Computes Zt(H,t)*Z*(H,t) for a single sample, sends result to g_num_all[i]\n",
    "    Zt_i = Zt(H_i, t)\n",
    "    g_num_all[i] = Zt_i*np.conj(Zt_i)\n",
    "    sqrt_g_den_all[i] = Z(H_i)\n",
    "\n",
    "def g_par(H_all, t, n_jobs=N_JOBS): # <-- makes more sense to parallelize over samples, not time-steps\n",
    "    g_num_all = np.zeros(H_all.shape[0], dtype=np.complex128)\n",
    "    sqrt_g_den_all = np.zeros(H_all.shape[0], dtype=np.complex128)\n",
    "    Parallel(n_jobs=n_jobs)(delayed(g_i)(H_all[i], t, g_num_all, sqrt_g_den_all, i) for i in range(H_all.shape[0]))\n",
    "\n",
    "    g_num = np.mean(g_num_all, axis=0)\n",
    "    g_den = np.mean(sqrt_g_den_all, axis=0)**2\n",
    "    return g_num/g_den\n",
    "\n",
    "# test for a single timestep\n",
    "test_t = 12\n",
    "\n",
    "tic = time.time()\n",
    "g_par_test = g_par(H_all, test_t)\n",
    "toc = time.time()\n",
    "duration = toc - tic\n",
    "print(f\"Single time-step, with parallelization: {duration//60} minutes, {duration%60} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all timesteps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_range_test = np.linspace(0,1,10)\n",
    "g_range_test = np.zeros(t_range_test.shape, dtype=np.complex128)\n",
    "\n",
    "tic = time.time()\n",
    "for i in len(g_range_test):\n",
    "    t_i = t_range_test[i]\n",
    "    g_i = g(H_all, t_i)\n",
    "    g_range_test[i] = g_i\n",
    "toc = time.time()\n",
    "duration = time.time() - tic "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phys417",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
